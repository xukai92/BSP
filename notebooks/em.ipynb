{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using InteractiveUtils, DrWatson, Comonicon\n",
    "if isdefined(Main, :IJulia) && Main.IJulia.inited\n",
    "    using Revise\n",
    "else\n",
    "    ENV[\"GKSwstype\"] = 100 # suppress warnings during gif saving\n",
    "end\n",
    "versioninfo()\n",
    "@quickactivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, ProgressMeter, Logging\n",
    "theme(:bright; size=(300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, Turing, BayesianSymbolic\n",
    "using ExprOptimization.ExprRules\n",
    "using PyCall\n",
    "pd = pyimport(\"pandas\")\n",
    "\n",
    "includef(args...) = isdefined(Main, :Revise) ? includet(args...) : include(args...)\n",
    "includef(srcdir(\"utility.jl\"))\n",
    "includef(srcdir(\"app_inf.jl\"))\n",
    "includef(srcdir(\"sym_reg.jl\"))\n",
    "includef(srcdir(\"network.jl\"))\n",
    "includef(srcdir(\"exp_max.jl\"))\n",
    "includef(srcdir(\"analyse.jl\"))\n",
    "includef(srcdir(\"dataset.jl\"))\n",
    "# Suppress warnings of using _varinfo\n",
    "with_logger(SimpleLogger(stderr, Logging.Error)) do\n",
    "    includef(srcdir(\"scenarios\", \"nbody.jl\"))\n",
    "    includef(srcdir(\"scenarios\", \"bounce.jl\"))\n",
    "    includef(srcdir(\"scenarios\", \"mat.jl\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function report_synth(dataset; rg_seed=1:5, rg_shuffleseed=1:5, namewithweak=false)\n",
    "    dataset = \"synth/$dataset\"\n",
    "    df = pd.DataFrame(\n",
    "        columns=(\"Method\", \"Normliased RMSE (train)\", \"Normliased RMSE (test)\", \"EM seed\", \"Data seed\")\n",
    "    )\n",
    "    forces = Dict{Int, Any}()\n",
    "\n",
    "    count = 1\n",
    "    @showprogress for seed in rg_seed, shuffleseed in rg_shuffleseed\n",
    "        hps = (ntrains=5, seed=seed, shuffleseed=shuffleseed)\n",
    "        if namewithweak\n",
    "            hps = (hps..., weak=false)\n",
    "        end\n",
    "\n",
    "        dir = datadir(dataset)\n",
    "        scenarios, attributes = loaddata(dir, hps.ntrains; shuffleseed=hps.shuffleseed)\n",
    "        scenarios_test, attributes_test = loaddata(dir, 20; shuffleseed=hps.shuffleseed, istrain=false)\n",
    "\n",
    "        local res\n",
    "        try\n",
    "            res = wload(resultsdir(dataset, savename(hps; connector=\"-\"), \"em.jld2\"))\n",
    "        catch\n",
    "            println(\"seed $(hps.seed) unfinished\")\n",
    "        end\n",
    "\n",
    "        @unpack ScenarioModel, latentname, ealg, malg, elike, mlike, trace = res\n",
    "\n",
    "        for (force, method) in [(trace[end].force, \"BSP\"), (ZeroForce(), \"Zero\")]\n",
    "            if method == \"BSP\"\n",
    "                forceexpr = BayesianSymbolic.get_executable(force.tree, force.grammar)\n",
    "                @info \"Count $count\" forceexpr\n",
    "                # Track expressions\n",
    "                forces[count] = (force.constant, forceexpr)\n",
    "            end\n",
    "            evalres = evalforce(ScenarioModel, scenarios, attributes, force, ealg, elike, mlike)\n",
    "            evalres_test = evalforce(ScenarioModel, scenarios_test, attributes_test, force, ealg, elike, mlike)\n",
    "\n",
    "            # Add to data frame\n",
    "            df.loc[count] = [method, evalres.normrmse, evalres_test.normrmse, seed, shuffleseed]\n",
    "            count = count + 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return df, forces\n",
    "end\n",
    "\n",
    "function savedf(df, dataset)\n",
    "    df.groupby([\"Method\"]).get_group(\"BSP\").to_csv(\"pretty_paper/raw/em-$dataset-bsp.csv\", columns=[\"Normliased RMSE (test)\", \"EM seed\", \"Data seed\"], header=false)\n",
    "    df.groupby([\"Method\"]).get_group(\"Zero\").to_csv(\"pretty_paper/raw/em-$dataset-zero.csv\", columns=[\"Normliased RMSE (test)\", \"EM seed\", \"Data seed\"], header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NBODY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, forces = report_synth(\"nbody\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedf(df, \"nbody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Method\"]).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Method\"]).quantile([.25, .75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOUNCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, forces = report_synth(\"bounce\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Method\"]).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Method\"]).quantile([.25, .75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, forces = report_synth(\"mat\"; rg_seed=0:9, rg_shuffleseed=-1:1, namewithweak=true)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Method\"]).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Method\"]).quantile([.25, .75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Method\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Method\"]).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Method\"]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"Method\"]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
